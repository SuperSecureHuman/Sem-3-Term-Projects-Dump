{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-30 20:30:33.415088: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-30 20:30:33.551594: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-12-30 20:30:34.237915: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/venom/miniconda3/lib/python3.8/site-packages/cv2/../../lib64:/home/venom/lib/:/usr/local/cuda/lib64::/usr/local/tensorrt/lib/\n",
      "2022-12-30 20:30:34.238042: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/venom/miniconda3/lib/python3.8/site-packages/cv2/../../lib64:/home/venom/lib/:/usr/local/cuda/lib64::/usr/local/tensorrt/lib/\n",
      "2022-12-30 20:30:34.238047: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# Create CNN using numpy\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "# Load data\n",
    "import keras.datasets.mnist as mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize data\n",
    "X_train = X_train/255.0\n",
    "X_test = X_test/255.0\n",
    "\n",
    "# Reshape data\n",
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# One-hot encoding\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crewate CNN using numpy\n",
    "class CNN:\n",
    "    def __init__(self, X_train, y_train, X_test, y_test, epochs, learning_rate, batch_size):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.loss = []\n",
    "        self.accuracy = []\n",
    "        self.val_loss = []\n",
    "        self.val_accuracy = []\n",
    "        self.history = {'loss': self.loss, 'accuracy': self.accuracy, 'val_loss': self.val_loss, 'val_accuracy': self.val_accuracy}\n",
    "        self.W1 = np.random.randn(3, 3, 1, 32) * np.sqrt(2/(3*3*1))\n",
    "        self.b1 = np.zeros((1, 1, 1, 32))\n",
    "        self.W2 = np.random.randn(3, 3, 32, 64) * np.sqrt(2/(3*3*32))\n",
    "        self.b2 = np.zeros((1, 1, 1, 64))\n",
    "        self.W3 = np.random.randn(7*7*64, 128) * np.sqrt(2/(7*7*64))\n",
    "        self.b3 = np.zeros((1, 128))\n",
    "        self.W4 = np.random.randn(128, 10) * np.sqrt(2/(128))\n",
    "        self.b4 = np.zeros((1, 10))\n",
    "        self.params = {'W1': self.W1, 'b1': self.b1, 'W2': self.W2, 'b2': self.b2, 'W3': self.W3, 'b3': self.b3, 'W4': self.W4, 'b4': self.b4}\n",
    "        \n",
    "    def batchedConv2d(self, X, W, b, stride, padding):\n",
    "        (m, n_H_prev, n_W_prev, n_C_prev) = X.shape\n",
    "        (f, f, n_C_prev, n_C) = W.shape\n",
    "        n_H = int((n_H_prev - f)/stride) + 1\n",
    "        n_W = int((n_W_prev - f)/stride) + 1\n",
    "        Z = np.zeros((m, n_H, n_W, n_C))\n",
    "        for h in range(n_H):\n",
    "            for w in range(n_W):\n",
    "                for c in range(n_C):\n",
    "                    vert_start = h*stride\n",
    "                    vert_end = vert_start + f\n",
    "                    horiz_start = w*stride\n",
    "                    horiz_end = horiz_start + f\n",
    "                    a_slice_prev = X[:, vert_start:vert_end, horiz_start:horiz_end, :]\n",
    "                    Z[:, h, w, c] = np.sum(a_slice_prev*W[:, :, :, c], axis=(1, 2, 3)) + b[:, :, :, c]\n",
    "        return Z\n",
    "\n",
    "    def relu(self, Z):\n",
    "        A = np.maximum(0, Z)\n",
    "        return A\n",
    "    \n",
    "    def maxpool2d(self, A, f, stride):\n",
    "        (n_H_prev, n_W_prev, n_C_prev) = A.shape\n",
    "        n_H = int((n_H_prev - f)/stride) + 1\n",
    "        n_W = int((n_W_prev - f)/stride) + 1\n",
    "        n_C = n_C_prev\n",
    "        A = A.reshape(n_H_prev, n_W_prev, n_C_prev)\n",
    "        Z = np.zeros((n_H, n_W, n_C))\n",
    "        for h in range(n_H):\n",
    "            for w in range(n_W):\n",
    "                for c in range(n_C):\n",
    "                    vert_start = h*stride\n",
    "                    vert_end = vert_start + f\n",
    "                    horiz_start = w*stride\n",
    "                    horiz_end = horiz_start + f\n",
    "                    a_prev_slice = A[vert_start:vert_end, horiz_start:horiz_end, c]\n",
    "                    Z[h, w, c] = np.max(a_prev_slice)\n",
    "        return Z\n",
    "\n",
    "    def flatten(self, A):\n",
    "        (n_H, n_W, n_C) = A.shape\n",
    "        A = A.reshape(n_H*n_W*n_C, 1)\n",
    "        return A\n",
    "\n",
    "    def softmax(self, Z):\n",
    "        A = np.exp(Z)/np.sum(np.exp(Z), axis=1, keepdims=True)\n",
    "        return A\n",
    "    \n",
    "    def forward_propagation(self, X):\n",
    "        Z1 = self.conv2d(X, self.W1, self.b1, 1, 1)\n",
    "        A1 = self.relu(Z1)\n",
    "        P1 = self.maxpool2d(A1, 2, 2)\n",
    "        Z2 = self.conv2d(P1, self.W2, self.b2, 1, 1)\n",
    "        A2 = self.relu(Z2)\n",
    "        P2 = self.maxpool2d(A2, 2, 2)\n",
    "        F = self.flatten(P2)\n",
    "        Z3 = F.dot(self.W3) + self.b3\n",
    "        A3 = self.relu(Z3)\n",
    "        Z4 = A3.dot(self.W4) + self.b4\n",
    "        A4 = self.softmax(Z4)\n",
    "        return A4\n",
    "    \n",
    "    def compute_cost(self, A4, y):\n",
    "        m = y.shape[0]\n",
    "        cost = -np.sum(y*np.log(A4))/m\n",
    "        return cost\n",
    "    \n",
    "    def conv2d_backward(self, dZ, X, W, b, stride, padding):\n",
    "        (n_H_prev, n_W_prev, n_C_prev) = X.shape\n",
    "        (f, f, n_C_prev, n_C) = W.shape\n",
    "        (n_H, n_W, n_C) = dZ.shape\n",
    "        dW = np.zeros((f, f, n_C_prev, n_C))\n",
    "        db = np.zeros((1, 1, 1, n_C))\n",
    "        dX = np.zeros((n_H_prev, n_W_prev, n_C_prev))\n",
    "        X_pad = np.pad(X, ((0, 0), (padding, padding), (padding, padding), (0, 0)), 'constant')\n",
    "        dX_pad = np.pad(dX, ((0, 0), (padding, padding), (padding, padding), (0, 0)), 'constant')\n",
    "        for h in range(n_H):\n",
    "            for w in range(n_W):\n",
    "                for c in range(n_C):\n",
    "                    vert_start = h*stride\n",
    "                    vert_end = vert_start + f\n",
    "                    horiz_start = w*stride\n",
    "                    horiz_end = horiz_start + f\n",
    "                    a_slice = X_pad[:, vert_start:vert_end, horiz_start:horiz_end, :]\n",
    "                    dX_pad[:, vert_start:vert_end, horiz_start:horiz_end, :] += W[:, :, :, c] * dZ[h, w, c]\n",
    "                    dW[:, :, :, c] += a_slice * dZ[h, w, c]\n",
    "                    db[:, :, :, c] += dZ[h, w, c]\n",
    "        dX = dX_pad[:, padding:-padding, padding:-padding, :]\n",
    "        return dX, dW, db\n",
    "    \n",
    "    def relu_backward(self, dA, Z):\n",
    "        dZ = np.array(dA, copy=True)\n",
    "        dZ[Z <= 0] = 0\n",
    "        return dZ\n",
    "    \n",
    "    def maxpool2d_backward(self, dA, A, f, stride):\n",
    "        (n_H_prev, n_W_prev, n_C_prev) = A.shape\n",
    "        (n_H, n_W, n_C) = dA.shape\n",
    "        dA = dA.reshape(n_H, n_W, n_C)\n",
    "        dX = np.zeros((n_H_prev, n_W_prev, n_C_prev))\n",
    "        for h in range(n_H):\n",
    "            for w in range(n_W):\n",
    "                for c in range(n_C):\n",
    "                    vert_start = h*stride\n",
    "                    vert_end = vert_start + f\n",
    "                    horiz_start = w*stride\n",
    "                    horiz_end = horiz_start + f\n",
    "                    a_prev_slice = A[vert_start:vert_end, horiz_start:horiz_end, c]\n",
    "                    mask = a_prev_slice == np.max(a_prev_slice)\n",
    "                    dX[vert_start:vert_end, horiz_start:horiz_end, c] += mask * dA[h, w, c]\n",
    "        return dX\n",
    "    \n",
    "    def flatten_backward(self, dA, A):\n",
    "        (n_H, n_W, n_C) = A.shape\n",
    "        dA = dA.reshape(n_H, n_W, n_C)\n",
    "        return dA\n",
    "\n",
    "    def softmax_backward(self, dA, Z):\n",
    "        dZ = dA\n",
    "        return dZ\n",
    "\n",
    "    def backward_propagation(self, X, y, A4):\n",
    "        m = y.shape[0]\n",
    "        dZ4 = A4 - y\n",
    "        dW4 = 1/m * A3.T.dot(dZ4)\n",
    "        db4 = 1/m * np.sum(dZ4, axis=0, keepdims=True)\n",
    "        dA3 = dZ4.dot(self.W4.T)\n",
    "        dZ3 = self.relu_backward(dA3, Z3)\n",
    "        dW3 = 1/m * F.T.dot(dZ3)\n",
    "        db3 = 1/m * np.sum(dZ3, axis=0, keepdims=True)\n",
    "        dF = dZ3.dot(self.W3.T)\n",
    "        dP2 = self.flatten_backward(dF, P2)\n",
    "        dA2 = self.maxpool2d_backward(dP2, A2, 2, 2)\n",
    "        dZ2 = self.relu_backward(dA2, Z2)\n",
    "        dP1, dW2, db2 = self.conv2d_backward(dZ2, P1, self.W2, self.b2, 1, 1)\n",
    "        dA1 = self.maxpool2d_backward(dP1, A1, 2, 2)\n",
    "        dZ1 = self.relu_backward(dA1, Z1)\n",
    "        dX, dW1, db1 = self.conv2d_backward(dZ1, X, self.W1, self.b1, 1, 1)\n",
    "        return dX, dW1, db1, dW2, db2, dW3, db3, dW4, db4\n",
    "    \n",
    "    def update_parameters(self, dW1, db1, dW2, db2, dW3, db3, dW4, db4):\n",
    "        self.W1 -= self.learning_rate * dW1\n",
    "        self.b1 -= self.learning_rate * db1\n",
    "        self.W2 -= self.learning_rate * dW2\n",
    "        self.b2 -= self.learning_rate * db2\n",
    "        self.W3 -= self.learning_rate * dW3\n",
    "        self.b3 -= self.learning_rate * db3\n",
    "        self.W4 -= self.learning_rate * dW4\n",
    "        self.b4 -= self.learning_rate * db4\n",
    "\n",
    "    def train(self, X, y, epochs, batch_size):\n",
    "        for i in range(epochs):\n",
    "            for j in range(0, X.shape[0], batch_size):\n",
    "                X_batch = X[j:j+batch_size]\n",
    "                y_batch = y[j:j+batch_size]\n",
    "                A4 = self.forward_propagation(X_batch)\n",
    "                cost = self.compute_cost(A4, y_batch)\n",
    "                dX, dW1, db1, dW2, db2, dW3, db3, dW4, db4 = self.backward_propagation(X_batch, y_batch, A4)\n",
    "                self.update_parameters(dW1, db1, dW2, db2, dW3, db3, dW4, db4)\n",
    "            if i % 10 == 0:\n",
    "                print(\"Cost after epoch %i: %f\" %(i, cost))\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        A4 = self.forward_propagation(X)\n",
    "        return np.argmax(A4, axis=1)\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        return np.mean(y_pred == y)\n",
    "    \n",
    "    def save(self, filename):\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(self, f)\n",
    "        \n",
    "    @staticmethod\n",
    "    def load(filename):\n",
    "        with open(filename, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"ConvolutionalNeuralNetwork(learning_rate={}, epochs={}, batch_size={})\".format(self.learning_rate, self.epochs, self.batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "# def __init__(self, X_train, y_train, X_test, y_test, epochs, learning_rate, batch_size):\n",
    "\n",
    "cnn = CNN(X_train, y_train, X_test, y_test , learning_rate=0.001, epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 28, 28, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/venom/repo/sem_proj/PML/CNN.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/venom/repo/sem_proj/PML/CNN.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m cnn\u001b[39m.\u001b[39;49mtrain(X_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m)\n",
      "\u001b[1;32m/home/venom/repo/sem_proj/PML/CNN.ipynb Cell 4\u001b[0m in \u001b[0;36mCNN.train\u001b[0;34m(self, X, y, epochs, batch_size)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/venom/repo/sem_proj/PML/CNN.ipynb#W3sZmlsZQ%3D%3D?line=180'>181</a>\u001b[0m X_batch \u001b[39m=\u001b[39m X[j:j\u001b[39m+\u001b[39mbatch_size]\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/venom/repo/sem_proj/PML/CNN.ipynb#W3sZmlsZQ%3D%3D?line=181'>182</a>\u001b[0m y_batch \u001b[39m=\u001b[39m y[j:j\u001b[39m+\u001b[39mbatch_size]\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/venom/repo/sem_proj/PML/CNN.ipynb#W3sZmlsZQ%3D%3D?line=182'>183</a>\u001b[0m A4 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward_propagation(X_batch)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/venom/repo/sem_proj/PML/CNN.ipynb#W3sZmlsZQ%3D%3D?line=183'>184</a>\u001b[0m cost \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_cost(A4, y_batch)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/venom/repo/sem_proj/PML/CNN.ipynb#W3sZmlsZQ%3D%3D?line=184'>185</a>\u001b[0m dX, dW1, db1, dW2, db2, dW3, db3, dW4, db4 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackward_propagation(X_batch, y_batch, A4)\n",
      "\u001b[1;32m/home/venom/repo/sem_proj/PML/CNN.ipynb Cell 4\u001b[0m in \u001b[0;36mCNN.forward_propagation\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/venom/repo/sem_proj/PML/CNN.ipynb#W3sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward_propagation\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/venom/repo/sem_proj/PML/CNN.ipynb#W3sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m     Z1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv2d(X, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mW1, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mb1, \u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/venom/repo/sem_proj/PML/CNN.ipynb#W3sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m     A1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(Z1)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/venom/repo/sem_proj/PML/CNN.ipynb#W3sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m     P1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmaxpool2d(A1, \u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m)\n",
      "\u001b[1;32m/home/venom/repo/sem_proj/PML/CNN.ipynb Cell 4\u001b[0m in \u001b[0;36mCNN.conv2d\u001b[0;34m(self, X, W, b, stride, padding)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/venom/repo/sem_proj/PML/CNN.ipynb#W3sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconv2d\u001b[39m(\u001b[39mself\u001b[39m, X, W, b, stride, padding):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/venom/repo/sem_proj/PML/CNN.ipynb#W3sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     \u001b[39mprint\u001b[39m(X\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/venom/repo/sem_proj/PML/CNN.ipynb#W3sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     (n_H_prev, n_W_prev, n_C_prev) \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/venom/repo/sem_proj/PML/CNN.ipynb#W3sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     (f, f, n_C_prev, n_C) \u001b[39m=\u001b[39m W\u001b[39m.\u001b[39mshape\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/venom/repo/sem_proj/PML/CNN.ipynb#W3sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     n_H \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m((n_H_prev \u001b[39m-\u001b[39m f \u001b[39m+\u001b[39m \u001b[39m2\u001b[39m\u001b[39m*\u001b[39mpadding)\u001b[39m/\u001b[39mstride) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "cnn.train(X_train, y_train, epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 11:38:47) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f401cf1dbab24df559ae8789ef7eacae25a0fecff741eceb08aecb7249ab0875"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
